{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 선형대수와 Numpy 프로그래밍 (2)\n",
    "> 머신러닝에 꼭 필요한 선형대수학 개념들을 배우고 이를 Numpy로 구현하는 방법을 배워봅시다.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Day 1]\n",
    "- permalink: /linear_algebra_with_numpy_2\n",
    "- exec: colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 시간에서 선형대수의 대략적인 개념과 numpy를 소개했습니다. 이번 챕터에서는 이제 본격적으로 내적, 행렬, 선형대수의 각종 연산들, 그리고 numpy의 고급 사용법에 대해 알아봅시다.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1. 내적 (Inner Product, Dot Product)\n",
    "\n",
    "이전 시간에 벡터와 벡터의 합, 벡터와 스칼라의 곱까지 다루었습니다. 이제 벡터와 벡터의 곱을 다뤄볼까 합니다. 벡터와 벡터를 곱하는 방법은 두가지가 있습니다. 첫번째는 내적, 두번째는 외적입니다. 내적, 외적은 어려워 보여서 많이들 꺼려하시는데요. 사실 그 이름의 의미만 알면 굉장히 쉬운 개념입니다. 우선 외/내적을 부를때, '적'은 한자로 '쌓을 적'에 해당하고(적재하다 할때 '적') 여기에서는 곱한다라고 이해하시면 됩니다. 그러면 왜 '내', '외'가 붙을까요?\n",
    "<br><br>\n",
    "\n",
    "\n",
    "먼저 내적은 벡터와 벡터를 곱하는 방법 중 하나입니다. **내적이라고 할때 '내'는 inner, 즉 안쪽을 의미**합니다. 왜 '내'적이냐면, **A $\\cdot$ B와 같이 내적할 때, B를 A가 존재하는 방향 '안'으로 넣은 상태에서 크기를 곱하기 때문**입니다. 그에 비해 외적은 B와 A 모두가 존재하는 방향의 '밖'에서 크기를 곱하기 때문에 '외'적이라고 부릅니다. (본 강의에서는 내적만 다룹니다. 실제 선형대수 전체 내용에서는 외적도 다루지만 머신러닝 프로그래밍을 할 때 여러분이 외적을 수행하는 경우는 거의 없습니다.)\n",
    "<br><br>\n",
    "\n",
    "그냥 길이만 곱하면 되지 무슨 어렵게 내적, 외적이냐고 하실 수 있는데, 기본적으로 벡터는 방향을 가진 데이터이기 때문에 더할때도 방향을 고려해줘야하고, 곱할 때도 방향을 맞추고 나서 계산해야합니다. 때문에 내적의 경우에는 두 요소 중 한 요소의 방향에 맞춘 뒤, 크기를 곱하는 것이고, 외적은 두 요소를 모두 새로운 방향에 놓고 크기를 곱하는 것입니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1.1. 벡터와 벡터의 내적 \n",
    "\n",
    "벡터와 벡터의 내적은 아래처럼 구합니다. 아래 애니메이션을 보면 $\\vec{v}$와 $\\vec{w}$를 내적하고 있습니다. 먼저 식($\\vec{v} \\cdot \\vec{w}$) 에서 뒷쪽에 있는 $\\vec{w}$를 $\\vec{v}$가 있는 방향 속으로 넣습니다. 이 것을 투영(projection)이라고 합니다.  \n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/71.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그리고 나서  $\\vec{w}$가 있는 공간으로 투영된 $\\vec{v}$와 $\\vec{w}$의 크기를 서로 곱합니다. 이렇게 '내'적은 한 요소를 다른 요소가 존재하는 공간 안으로 넣어서 크기를 곱하기 때문에 그러한 이름이 붙은 것입니다.\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/72.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "만약 두 벡터의 방향이 같다면 내적의 결과는 양수가 되고, 두 벡터가 수직이라면 다른 벡터에 투영했을 때, 길이가 0이 되므로 결과 값은 0이 됩니다. \n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/77.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그리고 만약 두 벡터가 방향이 반대라면, 내적의 결과는 음수가 됩니다.\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/73.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "내적을 계산할 땐, 대부분 cos을 사용해서 계산하는데요. $\\vec{v}$의 norm과 $\\vec{w}$의 norm을 그냥 곱하는 것이 아니라, $\\vec{v}$가 투영된 길이만큼 곱해야합니다. 투영된 길이가 바로 $\\vec{v} \\cos \\theta$입니다. \n",
    "\n",
    "![](https://qph.fs.quoracdn.net/main-qimg-234168ed4b95aa311a4cd1d8985253e7)\n",
    "<br><br>\n",
    "\n",
    "근데 매번 코사인 각도를 측정해서 계산하는 것은 너무 비효율적이고 복잡합니다. 따라서 우리는 주로 내적을 계산할 때 이렇게 계산하지 않고 아래처럼 계산합니다.\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/74.gif?raw=true)\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/75.gif?raw=true)\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/76.gif?raw=true)\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내적연산은 numpy의 @ 연산자를 통해 수행할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "vec_a = np.array([2, 1])\n",
    "vec_b = np.array([3, 2])\n",
    "\n",
    "vec_a @ vec_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계산 결과는 2 * 3 + 1 * 2로 8이 됩니다. 이렇게 계산한 방법과 위의 투영을 통한 cos곱과 결과가 같습니다. 이 둘이 왜 동일한 연산인지 이해하기 위해서는 아래부터 이야기할 행렬에 대한 이해가 필요합니다. 따라서 이 내용은 가장 마지막에 다시 이야기 하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 2. 행렬\n",
    "\n",
    "행렬은 이미 많이 들어봐서 알고 있을 것입니다. 그러나 행렬이 진정으로 무엇을 의미하는지는 학교에서 잘 가르쳐주지 않습니다. 행렬을 알기 전에 \"변환\", 즉 \"Transformation\"이라는 단어에 대해 먼저 생각해봅시다. <br><br>\n",
    "\n",
    "#### 2.1. 변환 (Transformation)\n",
    "\n",
    "변환은 함수와 어느정도 일맥상통합니다. 함수는 어떤 수를 입력받아서 다른 수로 변환합니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/31.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "선형대수의 맥락에서 보자면, 특정 벡터를 다른 벡터로 변환하는 것이라고 볼 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/32.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "즉 아래와 같이 어떤 입력벡터를 움직여서 출력 벡터로 만드는 것을 생각해볼 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/33.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이러한 변환을 공간 전체에 있는 모든 벡터에 적용한다면, 아래처럼 진행이 될 수 있습니다. 공간에 있는 모든 벡터가 위와 같이 회전하거나 변환됩니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/41.gif?raw=true)\n",
    "<br><br><br>\n",
    "\n",
    "#### 2.2. 선형 변환 (Linear Transformation)\n",
    "그러나, 선형대수에서는 모든 종류의 변환을 다루지 않습니다. 선형대수에서는 모든 벡터가 선형성을 유지해야하기 때문에 \"선형 변환\"에 대하서만 다루고, \"비 선형 변환\"은 다루지 않습니다. 시각적으로 볼 때, 변환이 선형적(Linear)하다는 것은 두가지 속성을 의미합니다. \n",
    "<br><br>\n",
    "\n",
    "- 모든 벡터는 변환 이후에도 휘지 않고 직선이여야 한다. \n",
    "- 원점은 변환 이후에도 그대로 원점(0, 0)이여야 한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "두가지 조건을 만족하지 않는 경우 선형변환이라고 하지 않습니다. 아래처럼 변환 이후에 직선이 휘어서 곡선이 되어있거나, 원점이 다른 곳으로 이동하면 그러한 변환은 선형변환이 아닌, 비선형 변환입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/42.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "#### 2.3. 굳이 변환 이야기를 꺼내는 이유?\n",
    "선형 변환에 대해서 말씀 드린 이유는, 행렬이 바로 벡터를 선형 변환시키기 위한 도구이기 때문입니다. 선형대수의 장점은 하나의 연산이나 하나의 벡터에 대해 기하학적인 표현과 수치적인 표현이 모두 가능하다는 것에 있다고 이전에 말했습니다. 저는 지금까지 행렬에 대해서 기하학적으로 열심히 설명했던 것 입니다. 그러면 이러한 변환을 우리가 어떻게 수치적으로 계산할 수 있을까요?\n",
    "<br><br>\n",
    "\n",
    "예를 들어 $\\vec{v}$ = $\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$라는 벡터가 변환 되었다고 합시다. 그러면 어떻게 이 변환 함수를 찾아낼 수 있을까요? 이 변환이 어떤 변환이였는지 계산하려면, 우리는 기저벡터가 어디에서 어디로 이동했는지만 알면 됩니다. 이 부분을 이해하기 위해서 앞 선 챕터에서 기저벡터에 대해 언급 했던 것 입니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "xy 평면공간의 정규직교 기저벡터는 $\\hat{i}$ = $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$과 $\\hat{j}$ = $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$입니다. 그리고 $\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$는 -1$\\hat{i}$ + 2$\\hat{j}$가 됩니다. 여기까지는 이전 챕터에서 이야기 했던 내용입니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/43.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "변환을 적용하면, 벡터가 움직인다고 했고, 기저벡터 역시 벡터이기 때문에 움직입니다. 자 이제, 변환이 적용된 이후에 기저벡터를 transformed $\\hat{i}$과 transformed $\\hat{j}$이라고 해보겠습니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/44.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "기존에 변환 전 $\\vec{v}$ = $\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}$ = -1 $\\hat{i}$ + 2 $\\hat{j}$ 였습니다. 마찬가지로 변환된 transformed $\\vec{v}$ = - 1 transformed $\\hat{i}$ + 2 transformed $\\hat{j}$로 이전의 비율(-1, 2)이 유지됩니다. <br><br>\n",
    "\n",
    "결론적으로 변환 전에 우리가 찾던 벡터 $\\vec{v}$(노란색)을 이루는 $\\hat{i}$와 $\\hat{j}$의 어떠한 선형결합이 변환 후에도 같은 결합으로 유지됩니다. 이 말은 즉, 단순히 $\\hat{i}$와 $\\hat{j}$가 변환 이후에 어디로 갔는지만 알면 벡터 $\\vec{v}$가 어디로 움직였는지도 알 수 있다는 말입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/45.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "변환 결과, 기저 $\\hat{i}$는 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$에서 $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$로 움직였고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$으로 움직였습니다. 따라서 변환된 벡터 $\\vec{v}$ = -1 * $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$ + 2 * $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$이 되고, 이 값은 $\\begin{bmatrix} 5 \\\\ 2 \\end{bmatrix}$로 변환된 $\\vec{v}$의 위치와 동일합니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/46.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이렇게 기저벡터가 어디로 움직였는지만 알면, 해당 공간의 모든 벡터가 어디로 움직였는지 알 수 있게 됩니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/47.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "#### 2.4. 행렬의 본질\n",
    "\n",
    "위의 내용을 정리해서 써봅시다. $\\hat{i}$는 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$에서 $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$로 움직였고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$으로 움직였습니다. 따라서 임의의 벡터 $\\vec{v}$ = $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$는 변환 후에 x * $\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$ + y * $\\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}$이 됩니다. 이것을 조금 더 정리해서 쓰면 $\\begin{bmatrix} 1x + 3y \\\\ -2x + 0y \\end{bmatrix}$가 됩니다. 이제 슬슬 감이 오시나요?\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/48.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그래서 이 선형 변환 자체를 $\\begin{bmatrix} 1 & 3 \\\\ -2 & 0 \\end{bmatrix}$와 같은 하나의 행렬로서 정의할 수 있습니다.\n",
    "즉, 행렬은 벡터의 위치를 선형 변환 시키는 도구라고 할 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/49.gif?raw=true)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shape\n",
    "\n",
    "행렬과 벡터의 Shape에 대해 알아봅시다. Shape이란 말 그대로, 행렬이나 벡터의 모양을 의미합니다.\n",
    "일반적으로 Shape은 (행의 수, 열의 수)로 표기합니다. 우리가 처음 봤던 가장 기본 형태인 2차원 벡터는 \n",
    "$\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$와 같이 표기합니다. 이와 같은 벡터는 (2, 1)의 Shape을 가진다고 할 수 있습니다. \n",
    "3차원 벡터인 $\\begin{bmatrix} 1 \\\\ -2 \\\\ 3 \\end{bmatrix}$는 행이 3개이므로 (3, 1)의 Shape를 갖고 \n",
    "$\\begin{bmatrix} 1 & 1 \\\\ -2 & 0 \\end{bmatrix}$과 같은 행렬은 (2, 2)의 Shape를 갖습니다.\n",
    "흔히, 이런 Shape을 2 x 2와 같이 표현하기도 합니다. numpy를 사용하면 행렬이나 벡터의 Shape을 매우 쉽게 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "# 행 2개, 열 1개\n",
    "vec_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 np.array 객체에 .shape를 붙이면 현재 객체의 shape를 알 수 있습니다.\n",
    "몇가지 예시를 더 보겠습니다.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_b = np.array([[1], \n",
    "                  [-2],\n",
    "                  [3]])\n",
    "\n",
    "# 행 3개, 열 1개\n",
    "vec_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "# 행 2개, 열 2개\n",
    "matrix_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 4. 행렬의 연산\n",
    "벡터 챕터에서는 가장 중요한 기본 연산인 벡터합과 스칼라 곱에 대해 배웠습니다. 행렬은 벡터보다 조금 더 다양한 연산을 가지고 있습니다. 아래에서 차례로 알아봅시다.\n",
    "<br><br>\n",
    "\n",
    "#### 4.1. 행렬 합 (= 벡터 합, Matrix Addition)\n",
    "행렬 합은 두 행렬을 더 합니다. 벡터 합과 동일한 방식으로 수행됩니다. 각 원소 자리에 있는 수를 더합니다.\n",
    "주의할 것은 벡터 합이나 행렬 합은 Shape가 동일할 때만 수행 가능합니다. Shape가 다른 경우 더할 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞는 경우 행렬 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [0, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape이 동일한 경우 (2, 2) & (2, 2)\n",
    "\n",
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "matrix_b = np.array([[1, 1], \n",
    "                     [2, 3]])\n",
    "\n",
    "matrix_a + matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞지 않는 경우 행렬 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a6ec0b31b5ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                      [2, 3, 7]])\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmatrix_a\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatrix_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# Shape 에러 발생!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2) (2,3) "
     ]
    }
   ],
   "source": [
    "# Shape이 다른 경우 (2, 2) & (2, 3)\n",
    "\n",
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "matrix_b = np.array([[1, 1, 0],\n",
    "                     [2, 3, 7]])\n",
    "\n",
    "matrix_a + matrix_b\n",
    "# Shape 에러 발생!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞는 경우 벡터 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape이 동일한 경우 (2, 1) & (2, 1)\n",
    "\n",
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "vec_b = np.array([[1], \n",
    "                  [2]])\n",
    "\n",
    "vec_a + vec_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shape이 맞지 않는 경우 벡터 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,1) (3,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9842e485b732>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 [2]])\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mvec_a\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvec_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# Shape 에러 발생!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,1) (3,1) "
     ]
    }
   ],
   "source": [
    "# Shape이 다른 경우 (2, 1) & (3, 1)\n",
    "\n",
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "vec_b = np.array([[1], \n",
    "                  [2],\n",
    "                  [2]])\n",
    "\n",
    "vec_a + vec_b\n",
    "# Shape 에러 발생!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 4.2. 스칼라 곱 (Scalar Multiplication)\n",
    "스칼라곱도 벡터에서 하던 방식과 동일하게 하면 됩니다. 모든 원소에 해당 스칼라를 곱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2],\n",
       "       [-4,  0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "scalar = 2\n",
    "\n",
    "matrix_a * scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 4.3. 원소곱 (Elementwise Multiplication)\n",
    "행렬의 각 자리 원소끼리 곱합니다. 행렬합과 마찬가지로 Shape이 동일해야합니다. * 연산자를 이용해 원소 곱 연산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2],\n",
       "       [-4,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_a = np.array([[1, 1], \n",
    "                     [-2, 0]])\n",
    "\n",
    "matrix_b = np.array([[2, 2],\n",
    "                     [2, 2]])\n",
    "\n",
    "matrix_a * matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "벡터도 원소 곱이 가능합니다만, 벡터의 정의에 해당하는 2가지 연산(벡터합, 스칼라곱)에 해당되지 않기 때문에 여기에서 소개합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2],\n",
       "       [-4]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "vec_b = np.array([[2], \n",
    "                  [2]])\n",
    "\n",
    "vec_a * vec_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 4.4. 행렬 - 벡터 내적 (Matrix - Vector Multiplication)\n",
    "위에서 말한 케이스로, 행렬을 통해 벡터를 선형변환 시키는 연산입니다. 일반적으로 $\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$ @ $\\begin{bmatrix} x \\\\ y \\end{bmatrix}$와 같은 연산이 있을 때, 대부분은 $\\begin{bmatrix} ax + by \\\\ cx + dy \\end{bmatrix}$와 같이 외우셨을 겁니다. (아래처럼)\n",
    "<br><br>\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/53.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그러나 본질은 여기에 있습니다. 왜 x에 a와 c가 곱해지는지, 왜 y왜 b와 d가 곱해지는지 알아야합니다. x에 a와 c가 곱해지는 이유는 x가 원래 x @ $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ = $\\begin{bmatrix} 1x \\\\ 0 \\end{bmatrix}$이였는데, $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$이 변환 이후에 $\\begin{bmatrix} a \\\\ b \\end{bmatrix}$로 변환되었기 때문에 x는 $\\begin{bmatrix} ax \\\\ cx \\end{bmatrix}$로 변환됩니다. y는 원래 y @ $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ = $\\begin{bmatrix} 0 \\\\ 1y \\end{bmatrix}$이였는데 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$이 변환 이후에 $\\begin{bmatrix} b \\\\ d \\end{bmatrix}$로 변환되었기 때문에  y는 $\\begin{bmatrix} by \\\\ dy \\end{bmatrix}$로 변환됩니다.\n",
    "<br><br>\n",
    "\n",
    "아래 수식을 보면 더 좋은 직관을 얻을 수 있을 것입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/50.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이 연산을 내적이라고 부르는 이유는 뒤에 있는 벡터가 앞에 있는 행렬의 방향으로 들어가기 때문입니다. 앞에 있는 행렬(변환)이 뒤의 벡터에 적용되어 방향이 변하기 때문에 이 연산을 우리는 '내적'이라고 부릅니다. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5. Shape 규칙 (Rule of multiplication)\n",
    "\n",
    "벡터와 행렬 혹은 행렬과 행렬을 내적하려면 내적하려는 두 벡터/행렬의 Shape이 맞아야합니다. 벡터 - 행렬 내적과 행렬 - 행렬 내적 (원소곱이 아닌 행렬 단위곱을 내적이라고 합니다.)에서는 아래와 같은 Shape에 대한 규칙이 있습니다. <br>\n",
    "\n",
    "\n",
    "![](https://2.bp.blogspot.com/-iuS-Uayk2FA/T_VUQ3nvaiI/AAAAAAAAAhs/ARvCwQFufsc/s1600/matrix_multi.png)\n",
    "<br>\n",
    "\n",
    "- Rule of multiplication : (a, b) * (b, d) → (a, d)\n",
    "- 앞쪽 벡터/행렬의 b와 뒤쪽 벡터/행렬의 b는 동일해야한다.\n",
    "- 계산결과 나오는 벡터/행렬의 Shape은 (a, d)가 된다.\n",
    "\n",
    "<br>\n",
    "\n",
    "이 규칙에 유의하여 계산해야하며, 연산에는 @라는 기호를 사용합니다. \n",
    "파이썬에서 * 는 원소곱을 의미하며 @는 내적을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1],\n",
       "       [ -2],\n",
       "       [-10]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape : (2, 1)\n",
    "vec_x = np.array([[1], \n",
    "                  [-2]])\n",
    "\n",
    "# Shape : (3, 2)\n",
    "mat_a = np.array([[1, 0],\n",
    "                  [0, 1],\n",
    "                  [0, 5]])\n",
    "\n",
    "# Shape : (3, 2) @ (2, 1) = (3, 1)\n",
    "mat_a @ vec_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### 4.6. 행렬 내적 (Matrix Multiplication)\n",
    "이제 조금 특별한 연산인 행렬 내적에 대해 소개합니다. 행렬과 행렬을 곱한다는 것은 (원소곱이 아니라 행렬 단위로 곱한다는 것) 합성함수를 만드는 것과 동일합니다. 변환에 변환을 적용하는 것은 함수에 함수를 적용하는 것과 동일한 이치이기 때문입니다.\n",
    "<br><br>\n",
    "\n",
    "여기에서 두가지 변환을 소개하겠습니다. 첫번째는 회전(Rotation)입니다. 여기서는 반시계방향으로 90도 회전해보겠습니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/51.gif?raw=true)\n",
    "\n",
    "회전하고나면 $\\hat{i}$는 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$에서 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$이 되고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}$이 됩니다. 따라서 이 변환은 $\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}$이 됩니다.\n",
    "<br><br>\n",
    "\n",
    "두번째는 기울이기(Shear)입니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/52.gif?raw=true)\n",
    "\n",
    "회전하고나면 $\\hat{i}$는 그대로 $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$이고, $\\hat{j}$는 $\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$에서 $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$이 됩니다. 따라서 이 변환은 $\\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$이 됩니다.\n",
    "<br><br>\n",
    "\n",
    "두 행렬을 $\\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$ @ $\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}$과 같이 행렬 곱하면 어떻게 될까요? 정답은 두 연산을 각각 실행하는 것이 됩니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/54.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "합성된 변환을 계산하면 아래처럼 계산할 수 있는데요. 각각 $\\hat{i}$와 $\\hat{j}$가 $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$과 $\\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}$으로 이동했기 때문에 합성 변환에 대한 행렬은 $\\begin{bmatrix} 1 & 1 \\\\ -1 & 0 \\end{bmatrix}$이 됩니다. 그리고 이 변환은 이전의 두 변환과는 다른 새로운 변환이 됩니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/55.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "만약 새로운 벡터가 이 변환에 적용된다면, 아래처럼 순서대로 두개의 행렬을 차례로 수행하게 되고, 이는 두 변환이 하나의 변환으로 합성된 것과 동일한 효과를 줍니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/56.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "수치적으로 행렬의 내적을 표현하면 다음과 같습니다. 가장 먼저 $\\hat{i}$가 움직일 곳을 찾습니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/57.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "기저벡터 $\\hat{i}$가 왼쪽의 행렬을 만나 변환되는 것을 생각하면 이 과정이 쉽게 이해 갈 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/58.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그리고 나서 $\\hat{j}$가 움직일 곳을 찾습니다. \n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/59.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "마찬가지로 기저벡터 $\\hat{j}$가 왼쪽의 행렬을 만나 변환되는 것을 생각하면 이 과정이 쉽게 이해 갈 수 있습니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/60.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이렇게 계산한 결과는 여러분이 기존에 아래처럼 계산한 결과와 동일하며, 실제로는 이 계산과정을 간단하게 마치 공식처럼 풀어낸 것입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/61.gif?raw=true)\n",
    "\n",
    "이렇게 계산하면 오른쪽 행렬에 있던 기저벡터들이 모두 왼쪽 행렬에 의해 변환된 것으로 생각 할 수 있습니다. <br><br>\n",
    "\n",
    "\n",
    "또한 기존에는 벡터와 행렬 한개만 가지고 변환하려고 했다면, 이 과정은 두개의 행렬을 미리 곱해서 합쳐놓고, 추후에 어떤 벡터가 입력되면 한번에 2개의 변환을 수행하는 것으로 생각 할 수도 있습니다. 이제 numpy를 이용해 행렬의 내적을 계산해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1],\n",
       "       [ 1,  0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shear = np.array([[1, 1], \n",
    "                  [0, 1]])\n",
    "\n",
    "rotation = np.array([[0, -1], \n",
    "                     [1, 0]])\n",
    "\n",
    "new_transform = shear @ rotation\n",
    "\n",
    "new_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = np.array([[2], \n",
    "                  [1]])\n",
    "\n",
    "new_vec_a = new_transform @ vec_a\n",
    "# shear와 반시계방향 90도 rotation 적용\n",
    "\n",
    "new_vec_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "마찬가지로 다양한 Shape의 행렬을 계산할 수 있습니다. 이 때 반드시 Shape 규칙을 따르게 됩니다. (Shape 규칙은 굉장히 중요합니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  8, 11, 14, 17],\n",
       "       [ 8, 13, 18, 23, 28],\n",
       "       [11, 18, 25, 32, 39]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape = (3, 2)\n",
    "mat_a = np.array([[1, 2], \n",
    "                  [2, 3], \n",
    "                  [3, 4]])\n",
    "\n",
    "# Shape = (2, 5)\n",
    "mat_b = np.array([[1, 2, 3, 4, 5], \n",
    "                  [2, 3, 4, 5, 6]])\n",
    "\n",
    "# Shape = (3, 2) @ (2, 5) = (3, 5)\n",
    "mat_a @ mat_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.7. 행렬내적의 교환법칙은 성립하지 않는다? \n",
    "한 가지 중요한 사항은 행렬내적은 교환법칙이 성립하지 않는다는 것입니다. A @ B와 B @ A가 같지 않습니다. 왜 그런지는 매우 단순한데, 순서를 바꿔서 움직이면 변환 결과가 달라지기 때문입니다. 만약 Shear를 먼저한다면 아래 처럼 움직입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/62.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "그러나 우리가 rotate 먼저 한다면 아래처럼 움직입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/63.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "두 결과가 매우 상이한데, 이는 매우 당연한 것입니다. 때문에 행렬을 곱할 때는 순서를 주의해줘야합니다. 회전 후 기울인 것과 기울이고 회전한 것의 결과가 다르기 때문이죠.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/64.gif?raw=true)\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8. 더 높은 차원의 행렬\n",
    "\n",
    "더 높은 차원에서의 행렬도 크게 다르지 않습니다. 2차원보다 높은 차원인 3차원에서의 연산도 크게 다르지 않습니다. 새로운 기저벡터인 $\\hat{k}$가 생긴 것 외에는 계산 방법은 동일합니다.\n",
    "<br><br>\n",
    "\n",
    "- $\\hat{i}$의 변환\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/66.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "- $\\hat{j}$의 변환\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/67.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "- $\\hat{k}$의 변환\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/68.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "\n",
    "마찬가지로 3차원 행렬은 3차원 공간상에서 벡터가 변환되는 과정을 나타낸 것입니다. 각각 열은 각 기저들 (i, j, k)이 어디로 움질일지를 나타내는 것입니다.\n",
    "\n",
    "![img](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/65.gif?raw=true)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.9. 벡터 - 벡터 내적 (Vector - Vector Multiplication)\n",
    "이제 가장 처음에 이야기 했던 벡터 내적에 대해 다시 이야기 해봅시다. 벡터의 내적은 한 벡터를 다른 벡터의 방향 안에 넣은 뒤, 투영된 길이와 다른 벡터의 길이를 곱하는 연산이라고 했습니다. 그렇다면 우리는 $\\vec{v} \\cdot \\vec{w}$의 연산을 다시 생각해볼 필요가 있습니다. 예를 하나 들어봅시다. $\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix}$를 벡터가 아닌 행렬로써 계산한다고 생각해봅시다. 사실 이 둘은 모두 Shape이 (2, 1)이기 때문에 행렬 내적으로 연산이 불가능합니다. \n",
    "<br><br>\n",
    "\n",
    "따라서 아래와 같이 연산하려면 조금 다르게 생각해야합니다.\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/74.gif?raw=true)\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/75.gif?raw=true)\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/76.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "먼저 앞의 벡터를 벡터로 생각하는게 아니라 뒤집어서 Shape이 (1, 2)인 행렬로 생각해봅시다. 그렇게 하면 (1, 2)의 행렬과 (2, 1)의 벡터를 곱해서 Shape이 (1, 1)인 단 하나의 Scalar가 되는데, 이 것이 바로 앞서 말한 벡터 내적입니다.\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/78.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "앞서서 행렬에 대해 이야기할 때, 행렬은 하나의 변환이라고 설명했습니다. 즉, (1, 2)의 행렬 자체가 한 벡터를 다른 벡터의 방향으로 보내는 변환이 된다는 것입니다. 그러한 변환을 만들기 위해서는 벡터 자기자신을 뒤집어서 (1, 2)의 Shape으로 만든 행렬로 만들면 된다는 것입니다.\n",
    "\n",
    "![image.png](https://github.com/gusdnd852/bigdata-lecture/blob/master/_notebooks/img/Day1/79.gif?raw=true)\n",
    "<br><br>\n",
    "\n",
    "이것에 대한 보다 자세한 디테일은 강의의 수준을 넘어갑니다. 자세한 내용은 3Blue 1Brown의 Linear Algebra 강의 Chapter 9번의 \"내적의 쌍대성\"을 보면 더욱 자세히 이해할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
